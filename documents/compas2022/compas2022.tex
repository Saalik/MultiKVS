% -*- mode: latex; coding: utf-8-unix -*-

% ===========================================================
%                              Choix de thématique
%===========================================================
% Une des quatre options 'parallelisme', 'architecture', 'systeme' 
% 'tempsreel' doit être utilisée avec le style compas2021
\documentclass[systeme,french,english]{compas2022}
\usepackage[utf8]{inputenc}
\usepackage{float}
\usepackage{algorithm2e}
\usepackage[table,x11names]{xcolor}
\usepackage[T1]{fontenc} %% Vector fonts
\usepackage[numbers,square,sort&compress]{natbib} %% Better bibliography
% \usepackage{parskip} \parskip=1ex plus 5pt minus 1pt \parindent=4ex %% indent paragraphs
\usepackage{xspace}  %% Macros with automatic spacing
\usepackage[defblank]{paralist}  %% inline lists

% \usepackage[utf8]{inputenc}
% \usepackage[T1]{fontenc}
% \usepackage[french]{babel}
% \usepackage{epsfig}
% \usepackage{amsmath}
% \usepackage{amssymb}
% \usepackage{euler}
% \usepackage{palatino}

%===========================================================
%                               Title
%===========================================================

\toappear{1} % Conserver cette ligne pour la version finale

\newcommand{\commentaire}[2][fromWhom?]{%
  {%
    \color{magenta}{\bfseries\sffamily\scriptsize$\triangleright$(#1:) #2$\triangleleft$}%
  }}

\begin{document}
\selectlanguage{english}

\title{Towards a correct, high-performance database backend}
\shorttitle{Correct High-Performance backend}

\author{Saalik Hatia(1), Annette Bieniusa(2), Carla Ferreira(3), Gustavo Petri(4), Marc Shapiro(1)}


\address{
  (1)~LIP6--Sorbonne-Université \& Inria, Paris, France  \\
  (2)~TU Kaiserslautern, Germany \\
  (3)~Universidade NOVA de Lisboa, Portugal \\
  (4)~ARM, Cambridge, United Kingdom\\
  }

\date{\today}

\maketitle

%===========================================================         %
%R\'esum\'e
%===========================================================  
\begin{abstract}
  This paper describes the design and implementation of a full-featured,
  high-performance geo-distributed database backend that is correct by
  construction.
  We develop hand-in-hand an operational semantics, key
  invariants, and a reference implementation.
  Our baseline is a simplistic backend that supports concurrent
  transactions storing and retrieving versions in an unbounded memory.
  Later steps add a single feature, such as persistence, journaling,
  caching, checkpointing, or sharding, to both the model and the
  implementation.
  We first prove (in Coq) that the baseline model satisfies its
  invariants and show (by testing) that the reference implementation
  satisfies the model.
  For each additional feature, we prove a simulation relation between
  the base and extended model, and similarly for the reference
  implementation.
  This paper focuses on the reference implementation: its relation
  between the model, and how we instrument the code with asserts and on
  the litmus tests.
  % At the time of writing, the operational semantics for several steps is
  % complete; the translation to Coq and the reference implementation are
  % ongoing.

  \MotsCles{
    système réparti,
    base de données géo-distribuée,
    vérification formelle,
    test
    }
\end{abstract}

% \tableofcontents

%=========================================================
\section{Introduction}
%=========================================================

Modern online applications use a distributed database management system
(DDBMS), whose storage backend provides users with available and
consistent data.
The purpose of a backend is conceptually simple: to store and retrieve
shared data.
However, for performance and fault-tolerance reasons, the internals of a
typical database backend are very complex, with many moving parts that interact
in hard-to-understand ways.
Existing backends are designed in a manual and ad-hoc manner;
inevitably, they have bugs that impact the consistency and integrity of
data.

Our research claim is that, for a complex system such as a database
backend, following a formal model helps the developer avoid bugs, and is
not in conflict with good performance.
In this work, we aim to to build a database backend that is correct by
design, while including some important optimisations (e.g., caching) and
properties (e.g., fault tolerance).

Formalising a backend that provide users with fast read and writes,
data safety and geo-replication is hard.
Any attempt to verify at once some monolithic specification that
includes all the interesting properties is probably doomed to failure.
Instead, we propose the an incremental approach,  decomposing the
system into a set of small, orthogonal modules and features.

Our starting baseline is a bare-bones backend, restricted to its
simplest function, i.e., transactions reading and writing data versions.
We formalise its operational semantics and specify its invariants.
We prove (in Coq) that the semantics satisfies the invariants.
We also provide a reference implementation (hand-written in Java), and
use litmus test cases to check that it follows the semantics and does
not violate the invariants.

Each design step adds a single feature, e.g., a cache or logging,
with its associated operational semantics and invariants.
We use simulation (or bisimulation) to show that the formal model is
equivalent without and with the feature, modulo the added constraints.
We take a similar approach with the reference implementation.
Furthermore, we compare performance without and with the feature.

Our ultimate aim is to show that the final design, including all the
features, is both correct (by simulation of the baseline) and has
comparable performance to ad-hoc database backends with similar features.

This paper gives some background on the formal model and focuses on the
system part, i.e., how the reference implementation follows the model,
how we instrument the invariants, and how we conduct the testing.

\section{Background}
\label{sec:background}

\subsection{Transactions and timestamps}
\label{sec:transactions}

A client of the backend executes transactions.
Classically, a transaction is a sequence of reads and updates, bounded by
a begin and an end.
The transaction either aborts with no effects; or it commits and all its
commits become visible atomically.
Formally, the choice between abort and commit is non-deterministic (in
practice it depends on the application's invariants and on external
events, such as sufficient resources being available).

We formalise the mutual ordering of transactions with abstract
\emph{timestamps}.
Committing a transaction $i$ assigns it a \emph{commit timestamp}
$\mathit{Ct}_{i}$; for atomicity, its updates are all labelled
with this same timestamp.
Conversely, a transaction $j$  has a \emph{snapshot timestamp} (or dependency
timestamp) $\mathit{Dt}_{j}$.
Transaction $i$ precedes transaction $j$ if $\mathit{Ct}_{i} \le
\mathit{Dt}_{j}$.
Transaction $j$ \emph{depends on} all transactions $i$ such $i$ precedes
$j$, meaning that a read that $j$ performs includes all the updates with
a label less or equal to $\mathit{Dt}_{j}$.
The set of such preceding updates is called the \emph{snapshot} of
transaction $j$.
 
For space reasons, this paper considers a single model, Transactional
Causal Plus Consistency (TCC+), i.e., causal consistency with
transactions and convergence \cite{rep:syn:sh228,rep:pro:sh182}.
Under TCC+, timestamps form a partial order (consistent with
happened-before), and a snapshot must be a causally-consistent cut.
However, our formalisation supports different transaction models (e.g.,
serialisable or snapshot-isolation), which differ only by timestamp
ordering being partial or total, and by constraints on beginning and
committing a transaction.

A transaction $t$ has the following attributes:
\begin{compactitem}
\item $\tau_{t}$: unique transaction identifier.
\item $\mathit{Dt}_{t}$: dependency timestamp.
\item {$\varepsilon_{t}$}: effect map, records the updates made by the
  transaction.
  A write updates the effect map.
\item ${R}_{t}$: read set, records the objects read by the transaction.
  A Read updates the read set.
\item $\mathit{Ct}_{t}$: commit timestamp, assigned if and when the
  transaction commits.
\item $\mathit{State}_{t}$: status, either \emph{not\_started}, \emph{live} or \emph{terminated}.
\end{compactitem}
In what follows, we omit the subscript if it is obvious from the context.

\subsection{Object-versions}

For generality, we consider that each update (or, more precisely, the
associated commit) creates a new version of the updated object.%
%
\footnote{
%
  This is standard for databases that use Multi-Version Concurrency
  Control (MVCC), but our model does not mandate MVCC in the
  implementation.
}
%
As mentioned above, each such version is labelled with the commit
timestamp of the corresponding transaction.
A particular version of a particular object maps the pair
$(\mathit{key},\mathit{Ct})$, where $\mathit{key}$ identifies the
object, to the corresponding value, which for the purposes of this paper
is an untyped ``\emph{blob}.''
In the above, $\mathit{key}$ is the unique identifier or key of the
object, and $\mathit{Ct}$ is the commit timestamp of the transaction
that writes this object-version.

% \begin{table}
%   \centering
%   \begin{tabular}{|c|c|c|c|}
%     \hline

%     API & Preconditions & Postconditions\\
%     \hline
%     startTransaction & $\mathit{State = null}$ & $\mathit{State = live}$\\
%     & &  \\
%     \hline
%     read & $\mathit{State = live}$ & $\mathit{R' = R \cup \{key\}}$\\
%     &  & \\
%     \hline
%     effect & $\mathit{State = live}$ & $\mathit{\varepsilon' = \varepsilon \cup \{(key, \tau)\}}$ \\
%     &  & \\
%     \hline
%     commit & $\mathit{State = live}$ & $\mathit{State = terminated}$\\
%     &  & $\mathit{Store' = Store \cup \varepsilon}$ \\
%     \hline
%     abort & $\mathit{State = live}$ & $\mathit{State = terminated}$ \\
%     &  &   \\
%     \hline

%   \end{tabular}
%   \caption{Unbounded-Memory Version store: Asserts and invariants for each API call}
%   \label{tab:AssertInvariantsUnbounded}
% \end{table}
\begin{table}
  \centering
  \begin{tabular}{c|c|c}
    ~                       & Precondition            & Postcondition \\
    \hline
    
    $\mathit{startTransaction()}$      & $\mathit{State = null}$ & $\mathit{State = live}$\\
                            & model-specific          & $                      $\\

    \hline

    $\mathit{update(key,u)}$& $\mathit{State = live}$ & $\mathit{\varepsilon' = \varepsilon \cup \{(key, u)\}}$ \\

    \hline

    $\mathit{read(key)}$    & $\mathit{State = live}$ & $\mathit{R' = R \cup \{key\}}$\\
    $\rightarrow{}r$        &                         & $r = \mathit{lookup(\varepsilon,key,Store,Dt)}$ \\

    \hline

    $\mathit{commit()}$     & $\mathit{State = live}$ & $\mathit{State = terminated}$\\
    model-specific          &                         & $\mathit{Store' = Store \cup \varepsilon}$ \\
                            &                         & $\mathit{Dt < Ct}$ \\
    \hline

    $\mathit{abort()}$      & $\mathit{State = live}$ & $\mathit{State = terminated}$ \\

  \end{tabular}

  % \commentaire[Marc]{@Saalik: Your postcondition for commit does not add the
  %   transaction tag!!!}\\ 
  % \commentaire[Saalik]{Because it's not supposed to be in the post conditions? 
  % I just say that at the end the Ct should be higher than the Dt}
  
  \caption{Unbounded-Memory Version store: pre- and post-conditions}
  \label{tab:AssertInvariantsUnbounded}
\end{table}

\section{Unbounded Version Store}

% \commentaire[Marc]{Pas strictement conforme au modèle : tu n'utilises pas les
%   transactions mais leurs timestamps.}

We start with an intuitive simple in-memory key-value store.
% Therefore if a crash or restart occurs the database is lost.
The implementation uses the Java \texttt{MultiMap<Key, Value>} for
storing the object versions.
% \commentaire[Marc]{Pourquoi pas une mappe <key+transaction, value>?}
Following Section~\ref{sec:transactions}, a Java Transaction object has
attributes \texttt{transactionID}, \texttt{EffectMap}, \texttt{ReadSet},
etc. 
In addition, to speed up processing, we explicitly store the
dependency graph of transactions.
% \commentaire[Marc]{Optimisation précoce~???}

The code is instrumented with Google Guava's \emph{checkArgument} library\cite{guava}
to perform assertions, both to check
arguments, and to make sure that the invariants specified in the model
are not violated, as we explain next, and as summarised in
Table~\ref{tab:AssertInvariantsUnbounded}.

For instance, an assert checks that the commit timestamp of a committed
transaction is greater than its dependency timestamp.
% \commentaire[Marc]{Pas une postcondition, mais un invariant : si non
  % commité, $Ct=+\infty$}.
To ensure that a client runs a sequence of well-formed transactions,
asserts check that every transactional operation (read, write, commit or
abort requests) takes place within a \emph{live} transaction, and that
only one transaction is live at a time.

Creating a transaction checks that its dependency timestamp $Dt$ is
valid, by calling a procedure that is specific to the consistency model.
For instance, in the TCC+ model, it checks that $Dt$ forms a
causally-consistent snapshot.

To update a key, the system adds the update to the effect buffer
associated with the transaction.%
%
\footnote{
%
  To simplify the notation, our postcondition assumes a key is updated
  only once per transaction.
}
%

Reading a key retrieves the key's value.
There are two cases.
If the transaction has previously updated the key, it returns the value
in the effect buffer.
Otherwise, it fetches the value corresponding to the transaction's
snapshot from the store, looking up the most recent version of the key
in the store whose timestamp is less or equal to $\mathit{Dt}$.
If the snapshot contains concurrent object-versions (i.e., written by
concurrent commits), they are merged \cite{syn:rep:sh143}.
If there is no preceding update in the store, it returns a default
value.
Finally, the system adds the key to the read-set $R$ of the transaction. 

When the client terminates the transaction, the system checks whether
the effects of $\varepsilon$ are valid according to the consistency model
(under TCC+, this is always the case).
The transaction commits only if this is true; this sets a commit
timestamp, and moves the updates
from the effect buffer into the store, tagged by the transactionID.
If not, the transaction aborts, by simply moving to the terminated
state.
A transaction may also abort non-deterministically.

\subsection{Bounded-Memory Version Store}

Our next step will be to impose a bound on the size of the store.

% \commentaire[Marc]{Stopped here **** 2022-04-16 10:40}
All invariants from the Unbounded memory are valid in this system.
We create a global value called $\mathit{M_{limit}}$ that contains the size 
limit for the $\mathit{Store}$.
We also keep track of current memory utilization represented by $\mathit{M_{used}}$.
To simplify our model we only consider the size of the $\mathit{Store}$, running transactions does not affect the invariant.
Based on these two variables we introduce a new system invariant:
\begin{itemize}
  \item \emph{$M_{used}$} $<$ \emph{$M_{limit}$}
\end{itemize}

Every time a transaction commits $\mathit{M_{used}}$ is updated to ensure that the size of the $\mathit{Store}$ does not grow beyond the limit set by the system.

If the threshold is reached, the system has two possibilities regarding running transactions, abort all running transaction or halt commits until an eviction of outdated Object-Version is performed.

For the eviction to happen safely, the system must ensure that every running transaction is able to read from its dependency snapshot.
To uphold the new system invariants, we keep track of all the dependencies of running transactions called \emph{RunningTr} but also all the commit timestamps of finished transactions \emph{CommitTr}.

We then introduce a new timestamp called Minimum Dependency $\mathit{MinDt}$.
\emph{MinDt} represents the oldest snapshot any running transaction is reading from.
When a transaction $\tau$ commits or aborts, it is removed from \emph{RunningTr}. 
If $\mathit{Dt= MinDt}$ and no other transaction is reading from $\mathit{Dt}$ the system advances \emph{MinDt} to the next oldest snapshot used in \emph{RunningTr}.

Eviction of Object-Version is done through a Garbage Collection.
The system performs a lookup on every key that is part of the snapshot $\mathit{MinDt}$.
Every Object-version in the $\mathit{Store}$ that has a commit timestamp that is lower than $\mathit{MinDt}$ and cannot be returned by a $\mathit{lookup(key,Store,minDt)}$ is evicted.

If at the end of the Garbage Collection the memory used is still higher than all the running transactions are aborted and we advance MinDt to allow additional garbage collection.


% \begin{table}
%   \centering
%   \begin{tabular}{|c|c|c|c|}
%     \hline
%     & & & \\
%     API & Preconditions & Invariants & Postconditions\\
%     & & & \\
%     \hline
%     startTransaction & $\mathit{State \neq live}$ & $\mathit{Ct \neq null => Dt > Ct}$ & $\mathit{State = live}$\\
%     & & $\mathit{Ct = null}$ & \\
%     \hline
%     read & $\mathit{State = live}$ & $\mathit{R' = R \cup \{key\}}$ &\\
%     & & $\mathit{Ct = null}$ & \\
%     \hline
%     effect & & $\mathit{State = live}$ & $\mathit{\varepsilon = \varepsilon \cup \{(key, \tau)\}}$ \\
%     & & $\mathit{Ct = null}$ & \\
%     \hline
%     \rowcolor{lightgray} commit & $\mathit{State = live}$ & $\mathit{M_{used} < M_{limit}}$ & $\mathit{Store' = Store \cup \varepsilon}$\\
%     \rowcolor{lightgray} & $\mathit{Ct = null}$ & & $\mathit{State = terminated}$ \\
%     \rowcolor{lightgray} & & & $\mathit{Dt \geq Ct}$ \\
%     \hline
%     abort & $\mathit{State = live}$ & $\mathit{Ct = null}$ & $\mathit{State = terminated}$\\
%     & & & \\
%     \hline

%   \end{tabular}
%   \caption{Bounded-Memory Version Store: Asserts and invariants for each API call}
%   \label{tab:AssertInvariantsBounded}
% \end{table}

% \subsubsection{Garbage collection}

% If a client attempts to commit and the memory used invariant is violated then the system performs a garbage collection by iterating through all the Object-versions.
% Every Object-version that has a commit timestamp that is lower than MinDt is removed from the backend.

% If at the end of the Garbage Collection the memory used is still higher than all the running transactions are aborted and we advance MinDt to allow additional garbage collection.

\section{Testing}

To simplify testing, every implementation is built with the same client interface. 

We start by executing a predetermined sequence of transactions and verify that the general behavior of the backend is correct.
Once this done we run randomized tests on both systems to check if the general behavior remains correct outside predefined scenarios.

The next step is to check if our invariants are upheld by our implementation.
Some invariants are directly inlined in the different functions.
For others like checking if every transactional operation takes place within a $\mathit{live}$ transaction, we run each operation at least once outside a $\mathit{live}$ transaction and expect our system to crash.

We want to show in our testing methodology that the Unbounded Version Store simulates the Bounded-Memory Version Store.
The Bounded-Memory version has a constraint on the minimum snapshot allowed to be used by the system.
So we execute the same sequence of transaction on both versions, where for every transaction the dependency snapshot is always higher than $\mathit{minDt}$ and expect to see the same results.
Then we execute a second sequence of transaction that has dependencies lower the minDt and show the differences between the two traces.
One execution should succeed where in the Bounded-Memory Version Store some transaction should abort.

Finally, we plan on performing performance experiments to show that our design has comparable performance to ad hoc database backend.

\section{Conclusion}

We have written several steps of the operational semantics, we have implemented the first partial versions of our design.
Later we plan on adding the following features to the database: persistency, Unbounded Journal, Bounded journal with checkpoints and finally a cache.

For each feature we will complete the operational semantics by adding the necessary invariants for maintaining safety.
Followed by a corresponding implementation matching our specification.
Through testing we show that our implementation simulates our operational semantics.
And that every step of the implementation simulate the following within the added constraints added by the new feature.
Finally, we will provide a translation of the model in Coq.



\bibliography{compas,predef,shapiro-bib-ext,shapiro-bib-perso}


\end{document}
